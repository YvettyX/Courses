Part 2 is about accident taxonomy and text preprocessing. According to the document Classification of enterprise employee casualties published by National Bureau of Standards on 8.1,1986, we usually classify those accidents into 10 types based on their causes. They are defined as Traffic Accident, Construction Accident, Fire Accident, Electric Shock Accident, Boat Accident, Chemical Accident, Mining Accident, Aviation Accident, Explosion Accident and Other Accident. Besides, according to the severity of them, there are four extra assessment levels. First, if an accident caused damage less than 10 million yuan, death toll less than 3, and the number of seriously injured less than 10, it will be defined as a level 1 accident. While the damage caused is more than 10 million yuan but less than 50 million yuan, the death toll is between 3 and 10, and the number of seriously injured is between 10 and 50, the accident is level 2 accident. If the damage is between 50 to 100 million yuan, the death toll is between 10 and 30, and the number of seriously injured is between 50 and 100, that is a level 3 accident. Furthermore, if unfortunately more than 100 million losses were caused, more than 30 people get killed or more than 100 people get badly injured, we call that a level 4 accident.
After acknowledging the rules of accident taxonomy, let me introduce the general steps of text preprocessing. In order to use computer to automatically classify data, we need to transfer the text from human language to machine-readable format for further processing. Since there is no obvious separator between two Chinese words, like the blank space in English, helping computer understand Chinese is even hard than understand English, so that text preprocessing plays a very important role in Chinese text classification. In the beginning, we have to filter the data. The raw data contains the information which can indicate where and when the accident occurred, the damage amount and a short description of the accident, which are useful to our classification. Except useful information there are also some terms we don’t need, such as preposition, conjunction and interjection. These words have little practical effect on text categorization, but they have a relatively high frequency of occurrence. If we also take these commonly used words into consideration, two texts with completely different themes would be difficult to separate. All of these information are mixed together in a unstructured format. To remove those disturbing terms, we need to separate word from word first, that step is called cutting words. Next step we use the regular expression module in Python (as re) to extract the keywords of time, location and death toll from the accident description text. After that, they would be stored as new attributes of accident data, and used as the basis for incident classification analysis. By filtering information, we can prevent the feature words from being overwhelmed. In fact, this extracting and removing procedure is a rough way to dimension reduction.
In order to further reduce the dimension, it is necessary to extract words which are more distinctive on the document classification, that is, feature selection step. We used the chi-square test to make feature selection. The basic idea of chi-square test can be roughly summarized as: considering the difference between the actual value and the theoretical value, and determining whether the theory can be established according to the magnitude of the difference.
The last step of preprocessing is vector space model building. Professor Salton 
from Conell University proposed the concept of Vector Space Model (VSM) in 1970 and applied it effectively to the SMART text retrieval system. In the VSM, every text is co-represented by a bunch of feature words, if the number of feature words is n, then we regard it as an n-dimensional vector on VSM. By using that model, we can express the natural language by a series of numbers, after that evaluating two texts’ semantic similarity turns into a feasible math question. Calculate the distance between two vectors in the space model, closer the distance, more likely the two texts are talking about one same theme. 

